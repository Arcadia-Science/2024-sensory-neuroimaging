{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze whole-brain activity\n",
    "* Uses `ImagingTrialLoader` to load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuroprocessing.imagingtrials import ImagingTrialLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "params = {\n",
    "        \"downsample_factor\": 8,\n",
    "        \"aligner_target_num_features\": 700,\n",
    "        \"secs_before_stim\": 60, # only process frames starting at X seconds before stimulus\n",
    "        \"preprocess_prefix\": \"aligned_downsampled_\",\n",
    "        \"process_prefix\": 'processed_',\n",
    "        \"s3fs_toplvl_path\": \"/Users/ilya_arcadia/arcadia-neuroimaging-pruritogens/Videos\",\n",
    "        \"local_toplvl_path\": \"/Users/ilya_arcadia/Neuroimaging_local/Processed/Injections/\",\n",
    "        \"load_from_s3\": False,\n",
    "        \"save_to_s3\": False,\n",
    "        'crop_px' : 20,\n",
    "        'bottom_percentile' : 5\n",
    "        }\n",
    "\n",
    "trials = ImagingTrialLoader(params)\n",
    "# exp_dates, trial_names = trials.filter_exp_and_trial_dirs(exp_dir=\"2024-03-20\", \n",
    "#                                                           limb = \"RHL\",\n",
    "#                                                         )\n",
    "exp_dates, trial_names = trials.filter_exp_and_trial_dirs()\n",
    "\n",
    "masks = trials.load_mask_files()\n",
    "traces = trials.load_traces()\n",
    "sync_infos = trials.get_sync_infos()\n",
    "# Plot the traces\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for trace, exp_date, trial_name, sync in zip(traces, exp_dates, trial_names, sync_infos):\n",
    "    t = (np.arange(0, len(trace))) / (sync['framerate_hz'] / params['downsample_factor']) - params['secs_before_stim']\n",
    "    trace = trace - trace[np.where(t >= 0)[0][0]]\n",
    "    ax.plot(t, trace, label=exp_date + ' ' + trial_name)\n",
    "# legend to the right of the plot\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "ax.axvline(x=0, color='r', linestyle='--')\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_ylabel('Response (a.u.)')\n",
    "# plot masks\n",
    "fig, axs = plt.subplots(ncols=len(masks), figsize=(15, 7))\n",
    "for ax, mask, exp_date, trial_name in zip(axs, masks, exp_dates, trial_names):\n",
    "    ax.imshow(mask, cmap='gray')\n",
    "    # remove axis ticks\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD and alignment to AI CCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wfield import load_stack, approximate_svd, chunk_indices, SVDStack, load_allen_landmarks, allen_load_reference, allen_transform_regions, atlas_from_landmarks_file\n",
    "from skimage import io\n",
    "from neuroprocessing.scripts.analysis import _identify_trial_save_paths\n",
    "import numpy as np\n",
    "import os, sys\n",
    "\n",
    "def _run_SVD(img_stack, n_SVD_components = 200):\n",
    "    \"\"\" Wrapper for wfield's SVD function\"\"\"\n",
    "\n",
    "    chunkidx = chunk_indices(len(img_stack),chunksize=256)\n",
    "    _frame_averages = []\n",
    "    for on,off in chunkidx:\n",
    "        _frame_averages.append(img_stack[on:off].mean(axis=0))\n",
    "\n",
    "    _frames_average = np.stack(_frame_averages).mean(axis = 0)\n",
    "    U,SVT = approximate_svd(img_stack, _frames_average, \n",
    "                            k = n_SVD_components,\n",
    "                            nframes_per_bin=10)\n",
    "    return _frames_average, U,SVT\n",
    "\n",
    "def reconstruct(u,svt,dims = None):\n",
    "    if dims is None:\n",
    "            dims = u.shape[:2]\n",
    "    return (u@svt).reshape((*dims,-1)).transpose(-1,0,1).squeeze()\n",
    "\n",
    "\n",
    "def run_SVD_and_alignment(exp_dir, trial_dir, params):\n",
    "    trial_path, save_path = _identify_trial_save_paths(exp_dir, trial_dir, params)\n",
    "    dat = load_stack(save_path / (params[\"preprocess_prefix\"] + trial_dir + \".tif\"))\n",
    "\n",
    "    frames_average, U,SVT = _run_SVD(dat, n_SVD_components = 2)\n",
    "\n",
    "    # reconstructed movie\n",
    "    mov = reconstruct(U,SVT).reshape(dat.nframes,1,*U.shape[:2])\n",
    "    mov = (mov*frames_average)+frames_average\n",
    "    # save SVD\n",
    "    np.save(save_path / ('U_' + params[\"process_prefix\"] + trial_dir + '.npy'), U)\n",
    "    np.save(save_path / ('SVT_' + params[\"process_prefix\"] + trial_dir + '.npy'), SVT)\n",
    "    np.save(save_path / ('frames_average_' + params[\"process_prefix\"] + trial_dir + '.npy'), frames_average)\n",
    "    io.imsave(save_path / ('svd_' + params[\"process_prefix\"] + trial_dir + '.tif'), mov.squeeze().astype(np.uint16))\n",
    "\n",
    "    from wfield.widgets import QApplication,RawViewer\n",
    "    app_args = ['/Users/ilya_arcadia/miniconda3/envs/neuro/bin/wfield', 'open_raw', trial_path]\n",
    "    app = QApplication(app_args)\n",
    "    w = RawViewer(raw = dat,\n",
    "                    mask = None,\n",
    "                    folder = trial_path,\n",
    "                    trial_onsets = None,\n",
    "                    reference = 'dorsal_cortex')\n",
    "    # close app\n",
    "    app.exec_()\n",
    "    \n",
    "    del dat\n",
    "\n",
    "    # AI alignment\n",
    "    basedir = '/Users/ilya_arcadia/Neuroimaging_local/Processed/wfield_testing/Zyla_30min_RHL_40ugin10uL_1pt5pctISO_1_1/wfield_results'\n",
    "    landmarks_json = os.path.join(trial_path,'dorsal_cortex_landmarks.json')\n",
    "    U = np.load(os.path.join(basedir, 'U.npy'))\n",
    "    SVT = np.load(os.path.join(basedir, 'SVT.npy'))\n",
    "\n",
    "    stack = SVDStack(U,SVT)\n",
    "    lmarks = load_allen_landmarks(os.path.join(basedir,'dorsal_cortex_landmarks.json'))\n",
    "\n",
    "    ccf_regions_reference,proj,brain_outline = allen_load_reference('dorsal_cortex')\n",
    "    # the reference is in allen CCF space and needs to be converted\n",
    "    # this converts to warped image space (accounting for the transformation)\n",
    "    ccf_regions = allen_transform_regions(None,ccf_regions_reference,\n",
    "                                        resolution = lmarks['resolution'],\n",
    "                                            bregma_offset = lmarks['bregma_offset'])\n",
    "    atlas, areanames, brain_mask = atlas_from_landmarks_file(landmarks_json) # this loads the atlas in transformed coords\n",
    "\n",
    "    # this does the transform (warps the original images)\n",
    "    # stack.set_warped(1, M = lmarks['transform']) # this warps the spatial components in the stack\n",
    "    stack.set_warped(False)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuroprocessing.scripts.analysis import process_trial\n",
    "params = {\n",
    "        \"downsample_factor\": 8,\n",
    "        \"aligner_target_num_features\": 700,\n",
    "        \"secs_before_stim\": 60, # only process frames starting at X seconds before stimulus\n",
    "        \"preprocess_prefix\": \"aligned_downsampled_\",\n",
    "        \"process_prefix\": 'processed_',\n",
    "        \"s3fs_toplvl_path\": \"/Users/ilya_arcadia/arcadia-neuroimaging-pruritogens/Videos\",\n",
    "        \"local_toplvl_path\": '/Users/ilya_arcadia/Neuroimaging_local/Processed/wfield_testing', # \"/Users/ilya_arcadia/Neuroimaging_local/Processed/Injections/\",\n",
    "        \"load_from_s3\": False,\n",
    "        \"save_to_s3\": False,\n",
    "        'crop_px' : 20,\n",
    "        'bottom_percentile' : 5\n",
    "        }\n",
    "run_SVD_and_alignment('2024-03-20-F1Num8REP', 'Zyla_15min_RHL_salineInj_1pt5pctISO_1', params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick script to calculate FFT of signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FFT of the ROI\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# get roi at center of image\n",
    "center = np.array(img.shape) // 2\n",
    "roi = img[:,center[1]-50:center[1]+50, center[2]-50:center[2]+50]\n",
    "roi_mean = np.mean(roi, axis=(1,2))\n",
    "# calculate heart rate using FFT\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.fft import fft, fftfreq\n",
    "\n",
    "fs = 10 # Hz\n",
    "t_orig = np.arange(0, len(roi_mean)) / fs\n",
    "roi_mean = roi_mean - np.mean(roi_mean)\n",
    "N = len(roi_mean)\n",
    "yf = fft(roi_mean)\n",
    "yf = 2.0/N * np.abs(yf[0:N//2])\n",
    "\n",
    "xf = fftfreq(N, 1/fs)[:N//2]\n",
    "f, axs = plt.subplots(2, 1)\n",
    "axs[0].plot(roi_mean)\n",
    "axs[0].set_xlim(0, 200)\n",
    "axs[1].plot(xf, yf)\n",
    "plt.xlim(0.5,3)\n",
    "plt.ylim(0, 3)\n",
    "\n",
    "# find peaks\n",
    "peaks, _ = find_peaks(yf, height=5, distance=10)\n",
    "plt.plot(xf[peaks], yf[peaks], \"x\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
