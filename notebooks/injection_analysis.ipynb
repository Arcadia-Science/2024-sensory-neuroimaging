{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tactile stim analysis script\n",
    "* Make sure to set `downsample_factor`, `secs_before_stim` correctly, as the values may differ from injection recordings.\n",
    "* Currently, `downsample_factor = 2`,  `secs_before_stim = 0`\n",
    "* Plot stimulus-triggered average image stack montage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser(description=(\n",
    "    'Run analysis (pre-process and processing steps).',\n",
    "    'Default parameters are loaded from `analysis_runs/default_analysis_params.json`.'))\n",
    "parser.add_argument('--reanalyze', action='store_true',\n",
    "                        help='If True, reanalyze all trials, even if already processed. Processed folders have a params.json file.')\n",
    "args = parser.parse_args('--reanalyze'.split())\n",
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporary testbed for csv parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuroprocessing.scripts.parse_csv import parse_csv, process_data\n",
    "\n",
    "df = parse_csv('/Users/ilya_arcadia/arcadia-neuroimaging-pruritogens/Videos/2024-02-29/Zyla_5min_RHLstim_2son4soff_1pt25pctISO_1/Zyla_5min_RHLstim_2son4soff_1pt25pctISO_1.csv')\n",
    "\n",
    "df.head()\n",
    "df_frames = process_data(\n",
    "    df,\n",
    "    col_camera=\"camera\",\n",
    "    col_stim='stim'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tactile stim preprocess/process test script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tactile stim STA montage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from neuroprocessing.imagingtrials import ImagingTrialLoader\n",
    "from skimage import io\n",
    "from skimage.util import montage\n",
    "\n",
    "params = {\n",
    "        \"downsample_factor\": 2,\n",
    "        \"secs_before_stim\": 0, # only process frames starting at X seconds before stimulus\n",
    "        \"preprocess_prefix\": \"aligned_downsampled_\",\n",
    "        \"process_prefix\": 'processed_',\n",
    "        \"s3fs_toplvl_path\": \"/Users/ilya_arcadia/arcadia-neuroimaging-pruritogens/Videos\",\n",
    "        \"local_toplvl_path\": \"/Users/ilya_arcadia/Neuroimaging_local/Processed/Injections/\",\n",
    "        \"load_from_s3\": False,\n",
    "        \"save_to_s3\": False,\n",
    "        'crop_px' : 20,\n",
    "        'bottom_percentile' : 5\n",
    "        }\n",
    "\n",
    "trials = ImagingTrialLoader(params)\n",
    "exp_dates, trial_names = trials.filter_exp_and_trial_dirs(exp_dir=\"2024-02-21\",\n",
    "                                                          limb='RHL',\n",
    "                                                          rec_time='5min',\n",
    "                                                        )\n",
    "\n",
    "# f = trials.plot_montage(50,500,10, montage_hw=(7,30))\n",
    "sta_list = trials.get_sta_stacks(2, 2)\n",
    "\n",
    "\n",
    "for sta, date, name in zip(sta_list, exp_dates, trial_names, strict=True):\n",
    "        # plot mean intensity of image over time\n",
    "        # ax.plot(sta[:,:,220:260,220:260].mean(axis=(2,3)).T)\n",
    "        # ax[0].imshow(sta[:,15:,:,:].mean(axis=1).mean(axis=0))\n",
    "        # ax[1].imshow(sta[:,:10,:,:].mean(axis=1).mean(axis=0))\n",
    "\n",
    "        sta_mean = (sta - sta[:,0,:,:][:,np.newaxis,:,:]).mean(axis=0)\n",
    "\n",
    "        n_plots = sta_mean.shape[0]\n",
    "\n",
    "        # assuming stim is in middle of stack\n",
    "        sta_diff = (sta[:,n_plots//2:,:,:].mean(axis=0) - sta[:,:n_plots//2,:,:].mean(axis=0)).mean(axis=0)\n",
    "        \n",
    "        # plot max projection of mean intensity of image over time\n",
    "        # f, ax = plt.subplots(1,1, figsize=(5,5))\n",
    "        # ax.imshow(sta_diff, cmap='viridis')\n",
    "        \n",
    "        # fig, axs = plt.subplots(nrows = n_plots-1, figsize=(10,50))\n",
    "\n",
    "        # for i in range(sta_mean.shape[0]-1):\n",
    "        #         axs[i].imshow(sta_mean[i+1], cmap='viridis', vmin=30000,vmax=40000)\n",
    "        #         axs[i].axis('off')\n",
    "\n",
    "        f,ax = plt.subplots(1,1, figsize=(10,10))\n",
    "        ax.imshow(montage(sta_mean,\n",
    "                                 fill = 0,\n",
    "                                 padding_width = 20,\n",
    "                                 rescale_intensity=False,\n",
    "                                 grid_shape= None,\n",
    "                                 # cmap='viridis',\n",
    "                                 ),\n",
    "                        cmap='viridis',\n",
    "                        vmin=30000,\n",
    "                        vmax=35000\n",
    "                        )\n",
    "        ax.axis('off')\n",
    "        ax.set_title(date + ' ' + name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tactile stim preprocess and process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuroprocessing.scripts.analysis import preprocess_and_process_trial\n",
    "\n",
    "params_stim = {\n",
    "    \"sync_csv_col\": \"stim\",\n",
    "    \"downsample_factor\": 2,\n",
    "    \"aligner_target_num_features\": 700,\n",
    "    \"secs_before_stim\": 0,\n",
    "    \"preprocess_prefix\": \"aligned_downsampled_\",\n",
    "    \"process_prefix\": \"processed_\",\n",
    "    \"s3fs_toplvl_path\": \"/Users/ilya_arcadia/arcadia-neuroimaging-pruritogens/Videos\",\n",
    "    \"local_toplvl_path\": \"/Users/ilya_arcadia/Neuroimaging_local/Processed/Injections/\",\n",
    "    \"load_from_s3\": True,\n",
    "    \"save_to_s3\": False,\n",
    "    \"crop_px\": 20,\n",
    "    \"bottom_percentile\": 5,\n",
    "    \"flood_connectivity\": 20,\n",
    "    \"flood_tolerance\" : 1000\n",
    "}\n",
    "\n",
    "preprocess_and_process_trial(\"2024-02-29\", \"Zyla_5min_RHLstim_2son4soff_1pt25pctISO_1\", params_stim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Injection analysis script\n",
    "* Uses `ImagingTrialLoader` to load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from neuroprocessing.imagingtrials import ImagingTrialLoader\n",
    "\n",
    "params = {\n",
    "        \"downsample_factor\": 8,\n",
    "        \"aligner_target_num_features\": 700,\n",
    "        \"secs_before_stim\": 60, # only process frames starting at X seconds before stimulus\n",
    "        \"preprocess_prefix\": \"aligned_downsampled_\",\n",
    "        \"process_prefix\": 'processed_',\n",
    "        \"s3fs_toplvl_path\": \"/Users/ilya_arcadia/arcadia-neuroimaging-pruritogens/Videos\",\n",
    "        \"local_toplvl_path\": \"/Users/ilya_arcadia/Neuroimaging_local/Processed/Injections/\",\n",
    "        \"load_from_s3\": False,\n",
    "        \"save_to_s3\": False,\n",
    "        'crop_px' : 20,\n",
    "        'bottom_percentile' : 5\n",
    "        }\n",
    "\n",
    "trials = ImagingTrialLoader(params)\n",
    "exp_dates, trial_names = trials.filter_exp_and_trial_dirs(exp_dir=\"2024-03-20-F1Num8REP\",\n",
    "                                                          limb='RHL'\n",
    "                                                        )\n",
    "# exp_dates, trial_names = trials.filter_exp_and_trial_dirs()\n",
    "\n",
    "masks = trials.load_mask_files()\n",
    "traces = trials.load_traces()\n",
    "sync_infos = trials.get_sync_infos()\n",
    "# Plot the traces\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "for trace, exp_date, trial_name, sync in zip(traces, exp_dates, trial_names, sync_infos, strict=True):\n",
    "    t = (np.arange(0, len(trace))) / (sync['framerate_hz'] / params['downsample_factor']) - params['secs_before_stim']\n",
    "    trace = trace - trace[np.where(t >= 0)[0][0]]\n",
    "    # remove slope\n",
    "    trace = trace - np.polyval(np.polyfit(t, trace, 1), t)\n",
    "    ax.plot(t, trace, label=exp_date + ' ' + trial_name)\n",
    "# legend to the right of the plot\n",
    "# ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "ax.axvline(x=0, color='r', linestyle='--')\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_ylabel('Response (a.u.)')\n",
    "ax.set_xlim([-50, 600])\n",
    "# plot masks\n",
    "fig, axs = plt.subplots(ncols=len(masks), figsize=(15, 7))\n",
    "for ax, mask, exp_date, trial_name in zip(axs, masks, exp_dates, trial_names):\n",
    "    ax.imshow(mask, cmap='gray')\n",
    "    # remove axis ticks\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(exp_date + ' ' + trial_name, fontsize=8)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD and alignment to AI CCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from neuroprocessing.scripts.analysis import _identify_trial_save_paths\n",
    "from skimage import io\n",
    "from wfield import (\n",
    "        SVDStack,\n",
    "        allen_load_reference,\n",
    "        allen_transform_regions,\n",
    "        approximate_svd,\n",
    "        atlas_from_landmarks_file,\n",
    "        chunk_indices,\n",
    "        load_allen_landmarks,\n",
    "        load_stack,\n",
    ")\n",
    "\n",
    "\n",
    "def _run_SVD(img_stack, n_SVD_components = 200):\n",
    "    \"\"\" Wrapper for wfield's SVD function\"\"\"\n",
    "\n",
    "    chunkidx = chunk_indices(len(img_stack),chunksize=256)\n",
    "    _frame_averages = []\n",
    "    for on,off in chunkidx:\n",
    "        _frame_averages.append(img_stack[on:off].mean(axis=0))\n",
    "\n",
    "    _frames_average = np.stack(_frame_averages).mean(axis = 0)\n",
    "    U,SVT = approximate_svd(img_stack, _frames_average, \n",
    "                            k = n_SVD_components,\n",
    "                            nframes_per_bin=10)\n",
    "    return _frames_average, U,SVT\n",
    "\n",
    "def _reconstruct(u,svt,dims = None):\n",
    "    \"\"\"Reconstruct the movie from the SVD components.\"\"\"\n",
    "    if dims is None:\n",
    "            dims = u.shape[:2]\n",
    "    return (u@svt).reshape((*dims,-1)).transpose(-1,0,1).squeeze()\n",
    "\n",
    "\n",
    "def run_SVD_and_alignment(exp_dir, trial_dir, params):\n",
    "    trial_path, save_path = _identify_trial_save_paths(exp_dir, trial_dir, params)\n",
    "    dat = load_stack(save_path / (params[\"preprocess_prefix\"] + trial_dir + \".tif\"))\n",
    "\n",
    "    frames_average, U,SVT = _run_SVD(dat, n_SVD_components = 2)\n",
    "\n",
    "    # reconstructed movie\n",
    "    mov = _reconstruct(U,SVT).reshape(dat.nframes,1,*U.shape[:2])\n",
    "    mov = (mov*frames_average)+frames_average\n",
    "    # save SVD\n",
    "    np.save(save_path / ('U_' + params[\"process_prefix\"] + trial_dir + '.npy'), U)\n",
    "    np.save(save_path / ('SVT_' + params[\"process_prefix\"] + trial_dir + '.npy'), SVT)\n",
    "    np.save(save_path / ('frames_average_' + params[\"process_prefix\"] + trial_dir + '.npy'), frames_average)\n",
    "    io.imsave(save_path / ('svd_' + params[\"process_prefix\"] + trial_dir + '.tif'), mov.squeeze().astype(np.uint16))\n",
    "\n",
    "    from wfield.widgets import QApplication, RawViewer\n",
    "    app_args = ['/Users/ilya_arcadia/miniconda3/envs/neuro/bin/wfield', 'open_raw', trial_path]\n",
    "    app = QApplication(app_args)\n",
    "    w = RawViewer(raw = dat,\n",
    "                    mask = None,\n",
    "                    folder = trial_path,\n",
    "                    trial_onsets = None,\n",
    "                    reference = 'dorsal_cortex')\n",
    "    # close app\n",
    "    app.exec_()\n",
    "\n",
    "    del dat\n",
    "\n",
    "    # AI CCF alignment\n",
    "    landmarks_json = os.path.join(trial_path,'dorsal_cortex_landmarks.json')\n",
    "    U = np.load(glob.glob(os.path.join(trial_path, 'U_*.npy'))[0])\n",
    "    SVT = np.load(glob.glob(os.path.join(trial_path, 'SVT_*.npy'))[0])\n",
    "\n",
    "    stack = SVDStack(U,SVT)\n",
    "    lmarks = load_allen_landmarks(os.path.join(trial_path,'dorsal_cortex_landmarks.json'))\n",
    "\n",
    "    ccf_regions_reference,proj,brain_outline = allen_load_reference('dorsal_cortex')\n",
    "    # the reference is in allen CCF space and needs to be converted\n",
    "    # this converts to warped image space (accounting for the transformation)\n",
    "    ccf_regions = allen_transform_regions(None,ccf_regions_reference,\n",
    "                                        resolution = lmarks['resolution'],\n",
    "                                            bregma_offset = lmarks['bregma_offset'])\n",
    "    atlas, areanames, brain_mask = atlas_from_landmarks_file(landmarks_json) # this loads the atlas in transformed coords\n",
    "\n",
    "    # this does the transform (warps the original images)\n",
    "    # stack.set_warped(1, M = lmarks['transform']) # this warps the spatial components in the stack\n",
    "    stack.set_warped(False)\n",
    "    return ccf_regions\n",
    "\n",
    "params = {\n",
    "        \"downsample_factor\": 8,\n",
    "        \"aligner_target_num_features\": 700,\n",
    "        \"secs_before_stim\": 60, # only process frames starting at X seconds before stimulus\n",
    "        \"preprocess_prefix\": \"aligned_downsampled_\",\n",
    "        \"process_prefix\": 'processed_',\n",
    "        \"s3fs_toplvl_path\": \"/Users/ilya_arcadia/arcadia-neuroimaging-pruritogens/Videos\",\n",
    "        \"local_toplvl_path\": '/Users/ilya_arcadia/Neuroimaging_local/Processed/wfield_testing',\n",
    "        \"load_from_s3\": False,\n",
    "        \"save_to_s3\": False,\n",
    "        'crop_px' : 20,\n",
    "        'bottom_percentile' : 5\n",
    "        }\n",
    "\n",
    "ccf = run_SVD_and_alignment('2024-03-20-F1Num8REP', 'Zyla_15min_RHL_salineInj_1pt5pctISO_1',\n",
    "                            params=params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate dorsal mask png using wfield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_allen_regions(ax, ccf_regions,\n",
    "                          resolution = 1,\n",
    "                          bregma_offset = np.array([0,0]),\n",
    "                          side_selection='both'):\n",
    "    '''\n",
    "    Plot the Allen CCF regions on a matplotlib axis.\n",
    "    '''\n",
    "\n",
    "    regs = []\n",
    "    for p in ccf_regions.iterrows():\n",
    "        c = p[1]\n",
    "        if side_selection in ['right','both']:\n",
    "            ax.plot(np.array(c.right_x)/resolution + bregma_offset[0],\n",
    "                    np.array(c.right_y)/resolution + bregma_offset[1], 'w')\n",
    "            # regs.append(hv.Curve(np.vstack([np.array(c.right_x)/resolution + bregma_offset[0],\n",
    "            #                                 np.array(c.right_y)/resolution + bregma_offset[1]]).T))\n",
    "        if side_selection in ['left','both']:\n",
    "            ax.plot(np.array(c.left_x)/resolution + bregma_offset[0],\n",
    "                    np.array(c.left_y)/resolution + bregma_offset[1], 'w')\n",
    "            # regs.append(hv.Curve(np.vstack([np.array(c.left_x)/resolution + bregma_offset[0],\n",
    "            #                                 np.array(c.left_y)/resolution + bregma_offset[1]]).T))\n",
    "    # invert y axis\n",
    "    return ax\n",
    "\n",
    "img = io.imread('/Users/ilya_arcadia/Neuroimaging_local/Processed/wfield_testing/2024-03-20-F1Num8REP/Zyla_15min_RHL_salineInj_1pt5pctISO_1/aligned_downsampled_Zyla_15min_RHL_salineInj_1pt5pctISO_1.tif')\n",
    "img_max = img.max(axis=0)\n",
    "del img\n",
    "f, ax = plt.subplots()\n",
    "# ax.imshow(img_max, cmap='gray')\n",
    "plot_allen_regions(ax, ccf, resolution = 1, bregma_offset = np.array([0,0]), side_selection='both')\n",
    "ax.set_axis_off()\n",
    "f.savefig('test.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick script to calculate FFT of signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FFT of the ROI\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.fft import fft, fftfreq\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# get roi at center of image\n",
    "center = np.array(img.shape) // 2\n",
    "roi = img[:,center[1]-50:center[1]+50, center[2]-50:center[2]+50]\n",
    "roi_mean = np.mean(roi, axis=(1,2))\n",
    "# calculate heart rate using FFT\n",
    "\n",
    "fs = 10 # Hz\n",
    "t_orig = np.arange(0, len(roi_mean)) / fs\n",
    "roi_mean = roi_mean - np.mean(roi_mean)\n",
    "N = len(roi_mean)\n",
    "yf = fft(roi_mean)\n",
    "yf = 2.0/N * np.abs(yf[0:N//2])\n",
    "\n",
    "xf = fftfreq(N, 1/fs)[:N//2]\n",
    "f, axs = plt.subplots(2, 1)\n",
    "axs[0].plot(roi_mean)\n",
    "axs[0].set_xlim(0, 200)\n",
    "axs[1].plot(xf, yf)\n",
    "plt.xlim(0.5,3)\n",
    "plt.ylim(0, 3)\n",
    "\n",
    "# find peaks\n",
    "peaks, _ = find_peaks(yf, height=5, distance=10)\n",
    "plt.plot(xf[peaks], yf[peaks], \"x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectrogram figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as io\n",
    "from scipy.interpolate import CubicSpline\n",
    "from scipy.signal import find_peaks, spectrogram\n",
    "\n",
    "\n",
    "def compute_breathing_rate(signal: np.array, fs:float) -> np.array:\n",
    "    \"\"\"Compute breathing rate from signal using spectrogram.\n",
    "    Args:\n",
    "        signal (np.ndarray): 1D array of signal\n",
    "        fs (float): sampling frequency\n",
    "    \n",
    "    Returns:\n",
    "        np.array: 1D numpy array of breathing rate, interpolated to be the same length as signal\n",
    "    \"\"\"\n",
    "\n",
    "    min_peak_height = 100 # minimum height of freq peak in spectrogram\n",
    "    min_breathing_freq, max_breathing_freq = 0.5, 2 # frequency range to look for breathing rate (Hz)\n",
    "    spectrogram_nperseg = 200 # number of samples per segment in spectrogram\n",
    "    spectrogram_noverlap = 50 # number of samples to overlap between segments in spectrogram\n",
    "\n",
    "\n",
    "    f, t, Sxx = spectrogram(signal, fs, nperseg=spectrogram_nperseg,\n",
    "                            noverlap=spectrogram_noverlap,\n",
    "                            detrend = 'linear')\n",
    "    plt.pcolormesh(t, f, Sxx, shading='gouraud')\n",
    "    plt.ylim(0, 3)\n",
    "\n",
    "\n",
    "    breathing_freqs = (f > min_breathing_freq) & (f < max_breathing_freq)\n",
    "    Sxx_breathing = Sxx[breathing_freqs]\n",
    "\n",
    "    # find peaks in spectrogram\n",
    "    f_peak_array = []\n",
    "    for i in range(Sxx_breathing.shape[1]):\n",
    "        peaks, _ = find_peaks(Sxx_breathing[:,i], height=min_peak_height, distance=4)\n",
    "        # if >1 peak, keep only highest\n",
    "        if len(peaks) > 0:\n",
    "            peaks = [peaks[np.argmax(Sxx_breathing[peaks, i])]]\n",
    "            f_peak = f[breathing_freqs][peaks]\n",
    "            f_peak_array.append(f_peak[0])\n",
    "        else:\n",
    "            f_peak_array.append(np.nan)\n",
    "\n",
    "    f_peak_array = np.array(f_peak_array)\n",
    "\n",
    "    # remove nans\n",
    "    t_peak_array = t[~np.isnan(f_peak_array)]\n",
    "    f_peak_array = f_peak_array[~np.isnan(f_peak_array)]\n",
    "    # plt.plot(t_peak_array,f_peak_array)\n",
    "\n",
    "    # interpolate back to be the same size as roi_mean\n",
    "    f_peak_interp = CubicSpline(t_peak_array, f_peak_array, bc_type='natural')\n",
    "\n",
    "    return f_peak_interp(np.arange(0, len(signal)) / fs)\n",
    "\n",
    "if 'img' not in locals():\n",
    "    img = io.imread('/Users/ilya_arcadia/arcadia-neuroimaging-pruritogens/Videos/2024-03-06/Zyla_15min_RHL_salineinj_1pt25pctISO_1/Zyla_15min_RHL_salineinj_1pt25pctISO_1_MMStack_Pos0.ome.tif')\n",
    "center = np.array(img.shape) // 2\n",
    "roi = img[:,center[1]-50:center[1]+50, center[2]-50:center[2]+50]\n",
    "roi_mean = np.mean(roi, axis=(1,2))\n",
    "f_breathing = compute_breathing_rate(roi_mean, fs = 10)\n",
    "# f,ax = plt.subplots()\n",
    "# plt.plot(f_breathing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot of FOV vs resolution for different microscopes at Arcadia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fovs = [13.7, 1, 10880, 151]\n",
    "res = [615, 2300, 11, 190]\n",
    "labels = ['Hina 4x', 'Hina 10x', 'Phenotypomat', 'UWFM']\n",
    "f,ax = plt.subplots(figsize=(3,3))\n",
    "plt.loglog(fovs,res, 'o')\n",
    "plt.ylabel('Resolution (px/mm)')\n",
    "plt.xlabel(r'Field of view $(mm{^2})$')\n",
    "# add labels\n",
    "for i, txt in enumerate(labels):\n",
    "    if txt.startswith('Phe'):\n",
    "        ax.annotate(txt, (fovs[i], res[i]), textcoords=\"offset points\", xytext=(-5,0), va='center',\n",
    "                    ha='right')\n",
    "    else:\n",
    "        ax.annotate(txt, (fovs[i], res[i]), textcoords=\"offset points\", xytext=(10,0), va='center')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
