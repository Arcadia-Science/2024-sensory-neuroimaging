{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect experimental data and process csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "from natsort import natsorted\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from neuroprocessing.scripts.parse_csv import parse_csv, process_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_sync_info(sync_csv_path):\n",
    "    \"\"\"Get dict of sync info (stim time, etc) from the sync csv file\n",
    "    \"\"\"\n",
    "    df_daq = parse_csv(sync_csv_path)\n",
    "\n",
    "    df_frames = process_data(\n",
    "        df_daq,\n",
    "        col_camera=\"camera\",\n",
    "        col_stim=\"button\"\n",
    "    )\n",
    "\n",
    "    stim_onset_frame = int(df_frames.loc[df_frames[\"stimulated\"], \"frame\"].iloc[0])\n",
    "    df_frames.set_index(\"frame\", inplace=True)\n",
    "    # print info\n",
    "    print(f\"Stimulus onset frame: {stim_onset_frame}\")\n",
    "    print(f\"Stimulus onset time (s): {df_frames.loc[stim_onset_frame, 'time']}\")\n",
    "    stim_duration_frames = sum(df_frames['stimulated'])\n",
    "    frame_time_s = df_frames.loc[stim_onset_frame, 'frametime']\n",
    "    framerate_hz = 1/frame_time_s\n",
    "\n",
    "    sync_info = {\n",
    "        \"stim_onset_frame\": stim_onset_frame,\n",
    "        \"stim_duration_frames\": stim_duration_frames,\n",
    "        \"frame_time_s\": frame_time_s,\n",
    "        \"framerate_hz\": framerate_hz\n",
    "    }\n",
    "    print(f\"Stimulus duration (frames): {stim_duration_frames}\")\n",
    "    print(f\"Stimulus duration (s): {stim_duration_frames/framerate_hz}\")\n",
    "    print(f\"Frame duration (ms): {frame_time_s*1000}\")\n",
    "    print(f\"Framerate (Hz): %.2f\" % (framerate_hz))\n",
    "    return sync_info\n",
    "\n",
    "def process_trial(trial_dir, params):\n",
    "    \"\"\"Process single trial\n",
    "    \n",
    "    Process a single imaging trial and save the processed tiff stack to the same directory as the original tiff stack.\n",
    "\n",
    "    An imaging trial can be split into 2+ videos due to tiff file size limits.\n",
    "\n",
    "    Stimulus is assumed to be in the first video.\n",
    "\n",
    "    Inputs:\n",
    "        trial_dir: str \n",
    "            Path to the directory containing pre-processed tiff stack\n",
    "        decimation_factor: int\n",
    "            Factor by which the stack has been decimated\n",
    "            **TODO** can probably hardcode the decimation factor below\n",
    "        sync_csv: Path or int\n",
    "            If Path, path to the sync csv file. If int, the frame number of the stimulus onset.\n",
    "    \"\"\"\n",
    "\n",
    "    # load sync json\n",
    "    with open(Path(trial_dir).parent / \"sync_info.json\", \"w\") as f:\n",
    "        sync_info = json.load(f)\n",
    "    \n",
    "\n",
    "    if type(tif_paths) == str:\n",
    "        tif_paths = [tif_paths]\n",
    "\n",
    "    # iterate through tifs and concatenate stacks\n",
    "    stack_stim = []\n",
    "    first_movie = True\n",
    "    for tif_path in tif_paths:\n",
    "        stack = io.imread(tif_path)\n",
    "        CROP_PX = 20\n",
    "        BOTTOM_PERCENTILE = 5\n",
    "        # crop image a little bit to remove the black border\n",
    "        stack = stack[:, CROP_PX:-CROP_PX, CROP_PX:-CROP_PX]\n",
    "\n",
    "        # not processing baseline frames for now\n",
    "        if first_movie:\n",
    "            # if first movie, add only the frames after the stimulus onset\n",
    "            stack_stim.append(stack[int((sync_info[\"stim_onset_frame\"]+100)/sync_info['decimation_factor']):, :, :])\n",
    "            first_movie = False\n",
    "        else:\n",
    "            # if subsequent movie, add all frames\n",
    "            stack_stim.append(stack)\n",
    "\n",
    "    stack_stim = np.concatenate(stack_stim, axis=0)\n",
    "    # find bottom X% of pixels in image\n",
    "    bottom10 = np.percentile(stack_stim, BOTTOM_PERCENTILE, axis=(1,2), keepdims=True).astype(np.uint16)\n",
    "    # subtract bottom X% from all pixels\n",
    "    stack_stim -= bottom10\n",
    "    stack_stim -= stack_stim.min(axis=0, keepdims=True)\n",
    "    stack_stim[stack_stim > 30000] = 0\n",
    "\n",
    "    # save tiff stack with the name of the first tiff in the stack\n",
    "    io.imsave(Path(tif_path).parent / (\"processed_\" + Path(tif_paths[0]).name), stack_stim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run\n",
    "* This processes a single trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# location where all experimental data is kept\n",
    "dir_experiments = Path(\"/Users/ilya_arcadia/Neuroimaging_local/Processed/Injections\")\n",
    "\n",
    "# path to a particular (or set of) experiment(s) for analysis\n",
    "date = \"2024-03-06\"\n",
    "expt = 'Zyla_30min_LHL_27mMhistinj_1pt75pctISO_1' # 'RHL_hist' # \"RHL_hist\" # LHL_saline\n",
    "fp_csv = natsorted((dir_experiments/date/expt).glob(\"*.csv\"))[0]\n",
    "fp_tifs = natsorted((dir_experiments/date/expt).glob(\"aligned*.tif\"))\n",
    "\n",
    "decimation_factor = 8\n",
    "img_d = process_trial(fp_tifs, decimation_factor, sync_csv=fp_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test out preprocessing steps (load, de-noising, and motion correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "preprocess_trial() missing 1 required positional argument: 'params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 43\u001b[0m\n\u001b[1;32m     38\u001b[0m     io\u001b[38;5;241m.\u001b[39mimsave(Path(trial_dir)\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;241m/\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maligned_downsampled_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m Path(fp_tifs[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mname), stack_aligned\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint16))\n\u001b[1;32m     40\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdownsample_factor\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m     42\u001b[0m }\n\u001b[0;32m---> 43\u001b[0m preprocess_trial(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/ilya_arcadia/Neuroimaging_local/Processed/Injections/2024-03-06/Zyla_30min_LHL_27mMhistinj_1pt75pctISO_1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: preprocess_trial() missing 1 required positional argument: 'params'"
     ]
    }
   ],
   "source": [
    "import json, tqdm\n",
    "from skimage.measure import block_reduce\n",
    "from neuroprocessing.align import StackAligner\n",
    "\n",
    "def preprocess_trial(trial_dir:str, params:dict):\n",
    "    \"\"\"Preprocessing of a single imaging trial\n",
    "\n",
    "    A single trial may have multiple videos due to tiff file size limits.\n",
    "        1. Downsample the tiff stack\n",
    "        2. Motion correction\n",
    "    \"\"\"\n",
    "    fp_tifs = natsorted(Path(trial_dir).glob(\"Zyla*.tif\"))\n",
    "    fp_csv = natsorted(Path(trial_dir).glob(\"*.csv\"))[0]\n",
    "    sync_info = _get_sync_info(fp_csv)\n",
    "    # save sync info as json\n",
    "    with open(Path(trial_dir).parent / \"sync_info.json\", \"w\") as f:\n",
    "        json.dump(sync_info, f)\n",
    "    \n",
    "    params['downsample_factor'] = 8\n",
    "\n",
    "    stack_list = []\n",
    "    for fp_tif in fp_tifs:\n",
    "        stack_list.append(io.imread(fp_tif))\n",
    "\n",
    "    # Downsample image\n",
    "    stack_downsampled = block_reduce(np.concatenate(stack_list, axis=0), block_size=(params['downsample_factor'], 1, 1), func=np.mean)\n",
    "    del(stack_list)\n",
    "\n",
    "    aligner = StackAligner(\n",
    "            filepath=stack_downsampled # <<NOT WORKING NOW>> change to accept stack_downsampled!\n",
    "        )\n",
    "    aligner.align()\n",
    "    # some additional func to do the actual transformation?\n",
    "    \n",
    "    # save aligned stack\n",
    "    stack_aligned = aligner.stack_aligned\n",
    "\n",
    "    io.imsave(Path(trial_dir).parent / (\"aligned_downsampled_\" + Path(fp_tifs[0]).name), stack_aligned.astype(np.uint16))\n",
    "\n",
    "params = {\n",
    "    \"downsample_factor\": 8\n",
    "}\n",
    "preprocess_trial('/Users/ilya_arcadia/Neuroimaging_local/Processed/Injections/2024-03-06/Zyla_30min_LHL_27mMhistinj_1pt75pctISO_1',\n",
    "                 params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[10023.5  , 10636.125, 10876.625, ..., 15226.125, 15499.875,\n",
       "         15565.875],\n",
       "        [10264.875, 10857.25 , 11100.375, ..., 15353.375, 15657.875,\n",
       "         15666.   ],\n",
       "        [10490.125, 11041.125, 11399.5  , ..., 15780.625, 15954.5  ,\n",
       "         16059.875],\n",
       "        ...,\n",
       "        [ 8071.5  ,  8093.625,  7888.   , ...,  5683.375,  5685.375,\n",
       "          5881.75 ],\n",
       "        [ 8288.875,  8223.   ,  8104.875, ...,  5801.875,  5849.5  ,\n",
       "          6100.375],\n",
       "        [ 8222.125,  8283.5  ,  8343.375, ...,  6093.625,  6090.375,\n",
       "          6204.125]],\n",
       "\n",
       "       [[ 9936.375, 10569.125, 10759.   , ..., 15151.   , 15636.25 ,\n",
       "         15733.25 ],\n",
       "        [10186.75 , 10792.875, 11028.125, ..., 15467.   , 15822.   ,\n",
       "         15764.875],\n",
       "        [10418.375, 11061.125, 11241.125, ..., 15707.625, 15823.   ,\n",
       "         16193.375],\n",
       "        ...,\n",
       "        [ 8168.375,  8115.75 ,  7919.375, ...,  5693.75 ,  5805.75 ,\n",
       "          5883.   ],\n",
       "        [ 8200.   ,  8177.5  ,  8124.375, ...,  5845.25 ,  5848.625,\n",
       "          5962.25 ],\n",
       "        [ 8256.125,  8179.375,  8326.625, ...,  5995.75 ,  6015.25 ,\n",
       "          6088.875]],\n",
       "\n",
       "       [[10042.   , 10557.5  , 10897.125, ..., 15184.25 , 15467.375,\n",
       "         15640.   ],\n",
       "        [10248.   , 10811.375, 11046.25 , ..., 15402.625, 15834.625,\n",
       "         15659.5  ],\n",
       "        [10520.75 , 11024.125, 11316.5  , ..., 15754.125, 15897.875,\n",
       "         16060.625],\n",
       "        ...,\n",
       "        [ 8087.75 ,  8092.125,  7812.25 , ...,  5689.75 ,  5810.625,\n",
       "          5856.375],\n",
       "        [ 8203.5  ,  8160.75 ,  8182.75 , ...,  5754.125,  5840.875,\n",
       "          5978.125],\n",
       "        [ 8212.25 ,  8152.875,  8321.875, ...,  6110.5  ,  5964.625,\n",
       "          6113.625]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 9393.125,  9701.25 , 10092.25 , ..., 14229.25 , 14234.125,\n",
       "         14521.5  ],\n",
       "        [ 9450.5  ,  9879.875, 10014.375, ..., 14196.125, 14245.125,\n",
       "         14332.875],\n",
       "        [ 9575.5  , 10059.875, 10344.375, ..., 14328.125, 14646.875,\n",
       "         14648.875],\n",
       "        ...,\n",
       "        [ 7993.25 ,  7741.625,  7789.   , ...,  5668.875,  5798.   ,\n",
       "          5835.5  ],\n",
       "        [ 8052.25 ,  7912.375,  7924.375, ...,  5700.5  ,  5924.   ,\n",
       "          6003.625],\n",
       "        [ 8032.25 ,  8038.   ,  8185.5  , ...,  5978.875,  5958.125,\n",
       "          6203.625]],\n",
       "\n",
       "       [[ 9454.625,  9839.75 , 10038.125, ..., 14061.5  , 14241.375,\n",
       "         14454.75 ],\n",
       "        [ 9472.125, 10030.875, 10141.25 , ..., 14131.625, 14324.25 ,\n",
       "         14448.75 ],\n",
       "        [ 9765.625, 10033.625, 10251.375, ..., 14355.875, 14466.   ,\n",
       "         14561.625],\n",
       "        ...,\n",
       "        [ 7961.125,  7764.375,  7729.625, ...,  5627.5  ,  5701.125,\n",
       "          5876.75 ],\n",
       "        [ 8058.125,  8079.5  ,  7929.   , ...,  5841.75 ,  5932.875,\n",
       "          5947.375],\n",
       "        [ 8094.   ,  8080.25 ,  8258.   , ...,  5990.75 ,  5981.625,\n",
       "          6183.75 ]],\n",
       "\n",
       "       [[ 9382.875,  9708.   , 10021.875, ..., 14109.75 , 14314.25 ,\n",
       "         14531.   ],\n",
       "        [ 9422.5  ,  9914.875, 10187.25 , ..., 14208.375, 14274.125,\n",
       "         14432.625],\n",
       "        [ 9641.625,  9955.875, 10319.   , ..., 14385.625, 14516.625,\n",
       "         14747.875],\n",
       "        ...,\n",
       "        [ 8013.   ,  7805.25 ,  7695.125, ...,  5676.25 ,  5826.375,\n",
       "          5836.625],\n",
       "        [ 8072.875,  8090.5  ,  7906.625, ...,  5754.875,  5842.25 ,\n",
       "          6043.75 ],\n",
       "        [ 8124.625,  8051.625,  8235.   , ...,  5985.5  ,  6013.375,\n",
       "          6160.125]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
