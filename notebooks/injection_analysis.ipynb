{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate tactile stim STA videos\n",
    " * Show STA montage\n",
    " * Optionally, save TIFF stack of montage (to be converted to animated GIF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Generate the original 3D array\n",
    "r = np.random.rand(100, 50, 50)\n",
    "\n",
    "# Define a mask for a 10x10 subregion\n",
    "mask = np.zeros((50, 50), dtype=bool)\n",
    "mask[10:20, 10:20] = True\n",
    "\n",
    "# Extract the subregion for each 50x50 layer in the 100 layers\n",
    "x = r[:, mask]\n",
    "\n",
    "# x will now have the shape (100, 10, 10)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask.nonzero()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sta_img = sta[20, :, :]\n",
    "plt.imshow(sta_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from neuroprocessing.imagingtrials import ImagingTrialLoader\n",
    "from skimage import io\n",
    "from skimage.filters import gaussian\n",
    "from skimage.util import montage\n",
    "\n",
    "imaging_trials = ImagingTrialLoader('/Users/ilya_arcadia/Neuroimaging_local/Processed/Injections')\n",
    "imaging_trials.filter(exp_dir='2024-02-29',# \"2024-03-19\",\n",
    "limb='LHL',\n",
    "rec_time='5min',\n",
    "remainder='.*pt25pctISO_2'\n",
    ")\n",
    "\n",
    "show_montage = False\n",
    "flipLR = True\n",
    "sta_dir = 'rendered_STA'\n",
    "\n",
    "# make dir to save rendered images\n",
    "os.makedirs(sta_dir, exist_ok=True)\n",
    "\n",
    "ssc_roi = {\n",
    "    \"center\": (125,175),  # (x, y)\n",
    "    \"width\": 100,\n",
    "    \"height\": 100\n",
    "}\n",
    "for t in imaging_trials.trials:\n",
    "  sta = t.get_sta_stack(5,1, ) #\n",
    "  sta_mean = (sta - sta[:,0,:,:][:,np.newaxis,:,:]).mean(axis=0)\n",
    "\n",
    "  n_plots = sta_mean.shape[0]\n",
    "  # add xy blur to sta_mean image\n",
    "  sta_mean = gaussian(sta_mean, sigma=2, channel_axis=0)\n",
    "\n",
    "  # Flip left/right because the camera image is flipped\n",
    "\n",
    "  f,ax = plt.subplots(1,1, figsize=(10,10))\n",
    "\n",
    "  if show_montage:\n",
    "    if flipLR:\n",
    "      sta_mean = np.flip(sta_mean, axis=2)\n",
    "    ax.imshow(montage(sta_mean,\n",
    "                      fill = 0,\n",
    "                      padding_width = 20,\n",
    "                      rescale_intensity=False,\n",
    "                      grid_shape= None,\n",
    "                      ),\n",
    "            cmap='viridis',\n",
    "            vmin=30000,\n",
    "            vmax=40000\n",
    "            )\n",
    "    ax.axis('off')\n",
    "    ax.set_title(t)\n",
    "    # io.imsave(os.path.join(sta_dir, f'{t}_STA.tiff'), sta_mean[1:,:,:].astype(np.uint16))\n",
    "  else:\n",
    "    ax.imshow(sta_mean[20,:,:], cmap='viridis', vmin=30000, vmax=40000)\n",
    "    if flipLR:\n",
    "      ax.invert_xaxis()\n",
    "    ax.set_title(t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate whole-brain injection traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from neuroprocessing.imagingtrials import ImagingTrialLoader\n",
    "\n",
    "inj_trials = ImagingTrialLoader('/Users/ilya_arcadia/Neuroimaging_local/Processed/Injections')\n",
    "inj_trials.filter(exp_dir='2024-03-19',# \"2024-03-19\",\n",
    "                  limb='(L|R)HL$',\n",
    "                  # rec_time='15min',\n",
    "                  # injection_type='.*inj'\n",
    "                  # remainder='.*ISO_2'\n",
    ")\n",
    "\n",
    "# Plot the traces\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "for inj_trial in inj_trials:\n",
    "    t, trace = inj_trial.load_trace()\n",
    "    trace = trace - trace[np.where(t >= 0)[0][0]]\n",
    "    # remove slope\n",
    "    trace = trace - np.polyval(np.polyfit(t, trace, 1), t)\n",
    "    ax.plot(t, trace, label=inj_trial)\n",
    "# legend to the right of the plot\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "ax.axvline(x=0, color='r', linestyle='--')\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_ylabel('Response (a.u.)')\n",
    "# ax.set_xlim([-50, 600])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD and alignment to AI CCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from neuroprocessing.scripts.analysis import _identify_trial_save_paths\n",
    "from skimage import io\n",
    "from wfield import (\n",
    "        SVDStack,\n",
    "        allen_load_reference,\n",
    "        allen_transform_regions,\n",
    "        approximate_svd,\n",
    "        atlas_from_landmarks_file,\n",
    "        chunk_indices,\n",
    "        load_allen_landmarks,\n",
    "        load_stack,\n",
    ")\n",
    "\n",
    "\n",
    "def _run_SVD(img_stack, n_SVD_components = 200):\n",
    "    \"\"\" Wrapper for wfield's SVD function\"\"\"\n",
    "\n",
    "    chunkidx = chunk_indices(len(img_stack),chunksize=256)\n",
    "    _frame_averages = []\n",
    "    for on,off in chunkidx:\n",
    "        _frame_averages.append(img_stack[on:off].mean(axis=0))\n",
    "\n",
    "    _frames_average = np.stack(_frame_averages).mean(axis = 0)\n",
    "    U,SVT = approximate_svd(img_stack, _frames_average, \n",
    "                            k = n_SVD_components,\n",
    "                            nframes_per_bin=10)\n",
    "    return _frames_average, U,SVT\n",
    "\n",
    "def _reconstruct(u,svt,dims = None):\n",
    "    \"\"\"Reconstruct the movie from the SVD components.\"\"\"\n",
    "    if dims is None:\n",
    "            dims = u.shape[:2]\n",
    "    return (u@svt).reshape((*dims,-1)).transpose(-1,0,1).squeeze()\n",
    "\n",
    "\n",
    "def run_SVD_and_alignment(exp_dir, trial_dir, params):\n",
    "    trial_path, save_path = _identify_trial_save_paths(exp_dir, trial_dir, params)\n",
    "    dat = load_stack(save_path / (params[\"preprocess_prefix\"] + trial_dir + \".tif\"))\n",
    "\n",
    "    frames_average, U,SVT = _run_SVD(dat, n_SVD_components = 2)\n",
    "\n",
    "    # reconstructed movie\n",
    "    mov = _reconstruct(U,SVT).reshape(dat.nframes,1,*U.shape[:2])\n",
    "    mov = (mov*frames_average)+frames_average\n",
    "    # save SVD\n",
    "    np.save(save_path / ('U_' + params[\"process_prefix\"] + trial_dir + '.npy'), U)\n",
    "    np.save(save_path / ('SVT_' + params[\"process_prefix\"] + trial_dir + '.npy'), SVT)\n",
    "    np.save(save_path / ('frames_average_' + params[\"process_prefix\"] + trial_dir + '.npy'), frames_average)\n",
    "    io.imsave(save_path / ('svd_' + params[\"process_prefix\"] + trial_dir + '.tif'), mov.squeeze().astype(np.uint16))\n",
    "\n",
    "    from wfield.widgets import QApplication, RawViewer\n",
    "    app_args = ['/Users/ilya_arcadia/miniconda3/envs/neuro/bin/wfield', 'open_raw', trial_path]\n",
    "    app = QApplication(app_args)\n",
    "    w = RawViewer(raw = dat,\n",
    "                    mask = None,\n",
    "                    folder = trial_path,\n",
    "                    trial_onsets = None,\n",
    "                    reference = 'dorsal_cortex')\n",
    "    # close app\n",
    "    app.exec_()\n",
    "\n",
    "    del dat\n",
    "\n",
    "    # AI CCF alignment\n",
    "    landmarks_json = os.path.join(trial_path,'dorsal_cortex_landmarks.json')\n",
    "    U = np.load(glob.glob(os.path.join(trial_path, 'U_*.npy'))[0])\n",
    "    SVT = np.load(glob.glob(os.path.join(trial_path, 'SVT_*.npy'))[0])\n",
    "\n",
    "    stack = SVDStack(U,SVT)\n",
    "    lmarks = load_allen_landmarks(os.path.join(trial_path,'dorsal_cortex_landmarks.json'))\n",
    "\n",
    "    ccf_regions_reference,proj,brain_outline = allen_load_reference('dorsal_cortex')\n",
    "    # the reference is in allen CCF space and needs to be converted\n",
    "    # this converts to warped image space (accounting for the transformation)\n",
    "    ccf_regions = allen_transform_regions(None,ccf_regions_reference,\n",
    "                                        resolution = lmarks['resolution'],\n",
    "                                            bregma_offset = lmarks['bregma_offset'])\n",
    "    atlas, areanames, brain_mask = atlas_from_landmarks_file(landmarks_json) # this loads the atlas in transformed coords\n",
    "\n",
    "    # this does the transform (warps the original images)\n",
    "    # stack.set_warped(1, M = lmarks['transform']) # this warps the spatial components in the stack\n",
    "    stack.set_warped(False)\n",
    "    return ccf_regions\n",
    "\n",
    "params = {\n",
    "        \"downsample_factor\": 8,\n",
    "        \"aligner_target_num_features\": 700,\n",
    "        \"secs_before_stim\": 60, # only process frames starting at X seconds before stimulus\n",
    "        \"preprocess_prefix\": \"aligned_downsampled_\",\n",
    "        \"process_prefix\": 'processed_',\n",
    "        \"s3fs_toplvl_path\": \"/Users/ilya_arcadia/arcadia-neuroimaging-pruritogens/Videos\",\n",
    "        \"local_toplvl_path\": '/Users/ilya_arcadia/Neuroimaging_local/Processed/wfield_testing',\n",
    "        \"load_from_s3\": False,\n",
    "        \"save_to_s3\": False,\n",
    "        'crop_px' : 20,\n",
    "        'bottom_percentile' : 5\n",
    "        }\n",
    "\n",
    "ccf = run_SVD_and_alignment('2024-03-20-F1Num8REP', 'Zyla_15min_RHL_salineInj_1pt5pctISO_1',\n",
    "                            params=params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate dorsal mask png using wfield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_allen_regions(ax, ccf_regions,\n",
    "                          resolution = 1,\n",
    "                          bregma_offset = np.array([0,0]),\n",
    "                          side_selection='both'):\n",
    "    '''\n",
    "    Plot the Allen CCF regions on a matplotlib axis.\n",
    "    '''\n",
    "\n",
    "    regs = []\n",
    "    for p in ccf_regions.iterrows():\n",
    "        c = p[1]\n",
    "        if side_selection in ['right','both']:\n",
    "            ax.plot(np.array(c.right_x)/resolution + bregma_offset[0],\n",
    "                    np.array(c.right_y)/resolution + bregma_offset[1], 'w')\n",
    "            # regs.append(hv.Curve(np.vstack([np.array(c.right_x)/resolution + bregma_offset[0],\n",
    "            #                                 np.array(c.right_y)/resolution + bregma_offset[1]]).T))\n",
    "        if side_selection in ['left','both']:\n",
    "            ax.plot(np.array(c.left_x)/resolution + bregma_offset[0],\n",
    "                    np.array(c.left_y)/resolution + bregma_offset[1], 'w')\n",
    "            # regs.append(hv.Curve(np.vstack([np.array(c.left_x)/resolution + bregma_offset[0],\n",
    "            #                                 np.array(c.left_y)/resolution + bregma_offset[1]]).T))\n",
    "    # invert y axis\n",
    "    return ax\n",
    "\n",
    "img = io.imread('/Users/ilya_arcadia/Neuroimaging_local/Processed/wfield_testing/2024-03-20-F1Num8REP/Zyla_15min_RHL_salineInj_1pt5pctISO_1/aligned_downsampled_Zyla_15min_RHL_salineInj_1pt5pctISO_1.tif')\n",
    "img_max = img.max(axis=0)\n",
    "del img\n",
    "f, ax = plt.subplots()\n",
    "# ax.imshow(img_max, cmap='gray')\n",
    "plot_allen_regions(ax, ccf, resolution = 1, bregma_offset = np.array([0,0]), side_selection='both')\n",
    "ax.set_axis_off()\n",
    "f.savefig('test.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick script to calculate FFT of signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FFT of the ROI\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.fft import fft, fftfreq\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# get roi at center of image\n",
    "center = np.array(img.shape) // 2\n",
    "roi = img[:,center[1]-50:center[1]+50, center[2]-50:center[2]+50]\n",
    "roi_mean = np.mean(roi, axis=(1,2))\n",
    "# calculate heart rate using FFT\n",
    "\n",
    "fs = 10 # Hz\n",
    "t_orig = np.arange(0, len(roi_mean)) / fs\n",
    "roi_mean = roi_mean - np.mean(roi_mean)\n",
    "N = len(roi_mean)\n",
    "yf = fft(roi_mean)\n",
    "yf = 2.0/N * np.abs(yf[0:N//2])\n",
    "\n",
    "xf = fftfreq(N, 1/fs)[:N//2]\n",
    "f, axs = plt.subplots(2, 1)\n",
    "axs[0].plot(roi_mean)\n",
    "axs[0].set_xlim(0, 200)\n",
    "axs[1].plot(xf, yf)\n",
    "plt.xlim(0.5,3)\n",
    "plt.ylim(0, 3)\n",
    "\n",
    "# find peaks\n",
    "peaks, _ = find_peaks(yf, height=5, distance=10)\n",
    "plt.plot(xf[peaks], yf[peaks], \"x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectrogram figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as io\n",
    "from scipy.interpolate import CubicSpline\n",
    "from scipy.signal import find_peaks, spectrogram\n",
    "\n",
    "\n",
    "def compute_breathing_rate(signal: np.array, fs:float) -> np.array:\n",
    "    \"\"\"Compute breathing rate from signal using spectrogram.\n",
    "    Args:\n",
    "        signal (np.ndarray): 1D array of signal\n",
    "        fs (float): sampling frequency\n",
    "    \n",
    "    Returns:\n",
    "        np.array: 1D numpy array of breathing rate, interpolated to be the same length as signal\n",
    "    \"\"\"\n",
    "\n",
    "    min_peak_height = 100 # minimum height of freq peak in spectrogram\n",
    "    min_breathing_freq, max_breathing_freq = 0.5, 2 # frequency range to look for breathing rate (Hz)\n",
    "    spectrogram_nperseg = 200 # number of samples per segment in spectrogram\n",
    "    spectrogram_noverlap = 50 # number of samples to overlap between segments in spectrogram\n",
    "\n",
    "\n",
    "    f, t, Sxx = spectrogram(signal, fs, nperseg=spectrogram_nperseg,\n",
    "                            noverlap=spectrogram_noverlap,\n",
    "                            detrend = 'linear')\n",
    "    plt.pcolormesh(t, f, Sxx, shading='gouraud')\n",
    "    plt.ylim(0, 3)\n",
    "\n",
    "\n",
    "    breathing_freqs = (f > min_breathing_freq) & (f < max_breathing_freq)\n",
    "    Sxx_breathing = Sxx[breathing_freqs]\n",
    "\n",
    "    # find peaks in spectrogram\n",
    "    f_peak_array = []\n",
    "    for i in range(Sxx_breathing.shape[1]):\n",
    "        peaks, _ = find_peaks(Sxx_breathing[:,i], height=min_peak_height, distance=4)\n",
    "        # if >1 peak, keep only highest\n",
    "        if len(peaks) > 0:\n",
    "            peaks = [peaks[np.argmax(Sxx_breathing[peaks, i])]]\n",
    "            f_peak = f[breathing_freqs][peaks]\n",
    "            f_peak_array.append(f_peak[0])\n",
    "        else:\n",
    "            f_peak_array.append(np.nan)\n",
    "\n",
    "    f_peak_array = np.array(f_peak_array)\n",
    "\n",
    "    # remove nans\n",
    "    t_peak_array = t[~np.isnan(f_peak_array)]\n",
    "    f_peak_array = f_peak_array[~np.isnan(f_peak_array)]\n",
    "    # plt.plot(t_peak_array,f_peak_array)\n",
    "\n",
    "    # interpolate back to be the same size as roi_mean\n",
    "    f_peak_interp = CubicSpline(t_peak_array, f_peak_array, bc_type='natural')\n",
    "\n",
    "    return f_peak_interp(np.arange(0, len(signal)) / fs)\n",
    "\n",
    "if 'img' not in locals():\n",
    "    img = io.imread('/Users/ilya_arcadia/arcadia-neuroimaging-pruritogens/Videos/2024-03-06/Zyla_15min_RHL_salineinj_1pt25pctISO_1/Zyla_15min_RHL_salineinj_1pt25pctISO_1_MMStack_Pos0.ome.tif')\n",
    "center = np.array(img.shape) // 2\n",
    "roi = img[:,center[1]-50:center[1]+50, center[2]-50:center[2]+50]\n",
    "roi_mean = np.mean(roi, axis=(1,2))\n",
    "f_breathing = compute_breathing_rate(roi_mean, fs = 10)\n",
    "# f,ax = plt.subplots()\n",
    "# plt.plot(f_breathing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot of FOV vs resolution for different microscopes at Arcadia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fovs = [13.7, 1, 10880, 151]\n",
    "res = [615, 2300, 11, 190]\n",
    "labels = ['Hina 4x', 'Hina 10x', 'Phenotypomat', 'UWFM']\n",
    "f,ax = plt.subplots(figsize=(3,3))\n",
    "plt.loglog(fovs,res, 'o')\n",
    "plt.ylabel('Resolution (px/mm)')\n",
    "plt.xlabel(r'Field of view $(mm{^2})$')\n",
    "# add labels\n",
    "for i, txt in enumerate(labels):\n",
    "    if txt.startswith('Phe'):\n",
    "        ax.annotate(txt, (fovs[i], res[i]), textcoords=\"offset points\", xytext=(-5,0), va='center',\n",
    "                    ha='right')\n",
    "    else:\n",
    "        ax.annotate(txt, (fovs[i], res[i]), textcoords=\"offset points\", xytext=(10,0), va='center')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
