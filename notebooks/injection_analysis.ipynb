{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect experimental data and process csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "from natsort import natsorted\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from neuroprocessing.scripts.parse_csv import parse_csv, process_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_trial_save_paths(exp_dir:str, trial_dir:str, params:dict) -> tuple:\n",
    "    \"\"\"Identify the paths to the raw and processed tiff stacks for a single trial\n",
    "    \n",
    "    Inputs:\n",
    "        exp_dir: str\n",
    "            Name of the experiment directory e.g. \"2024-03-06\"\n",
    "        trial_dir: str\n",
    "            Name of the trial directory e.g. \"Zyla_30min_LHL_27mMhistinj_1pt75pctISO_1\n",
    "        params: dict\n",
    "            Run parameters\n",
    "    Returns:\n",
    "        tuple\n",
    "            (Path to the raw tiff stack, Path to the processed tiff stack)\n",
    "    \"\"\"\n",
    "    load_from_s3 = params[\"load_from_s3\"]\n",
    "    save_to_s3 = params[\"save_to_s3\"]\n",
    "    if load_from_s3:\n",
    "        print(\"Loading raw stack from S3\")\n",
    "    else:\n",
    "        print(\"Loading raw stack from local filesystem\")\n",
    "\n",
    "    trial_path = params[\"s3fs_toplvl_path\"] if load_from_s3 else params[\"local_toplvl_path\"]\n",
    "    save_path = params[\"s3fs_toplvl_path\"] if save_to_s3 else params[\"local_toplvl_path\"]\n",
    "\n",
    "    trial_path = Path(trial_path) / exp_dir / trial_dir\n",
    "    save_path = Path(save_path) / exp_dir / trial_dir\n",
    "    return (trial_path, save_path)\n",
    "\n",
    "def _get_sync_info(sync_csv_path):\n",
    "    \"\"\"Get dict of sync info (stim time, etc) from the sync csv file\n",
    "    \"\"\"\n",
    "    df_daq = parse_csv(sync_csv_path)\n",
    "\n",
    "    df_frames = process_data(\n",
    "        df_daq,\n",
    "        col_camera=\"camera\",\n",
    "        col_stim=\"button\"\n",
    "    )\n",
    "\n",
    "    stim_onset_frame = int(df_frames.loc[df_frames[\"stimulated\"], \"frame\"].iloc[0])\n",
    "    df_frames.set_index(\"frame\", inplace=True)\n",
    "    # print info\n",
    "    print(f\"Stimulus onset frame: {stim_onset_frame}\")\n",
    "    print(f\"Stimulus onset time (s): {df_frames.loc[stim_onset_frame, 'time']}\")\n",
    "    stim_duration_frames = sum(df_frames['stimulated'])\n",
    "    frame_time_s = df_frames.loc[stim_onset_frame, 'frametime']\n",
    "    framerate_hz = 1/frame_time_s\n",
    "\n",
    "    sync_info = {\n",
    "        \"stim_onset_frame\": stim_onset_frame,\n",
    "        \"stim_duration_frames\": stim_duration_frames,\n",
    "        \"frame_time_s\": frame_time_s,\n",
    "        \"framerate_hz\": framerate_hz\n",
    "    }\n",
    "    print(f\"Stimulus duration (frames): {stim_duration_frames}\")\n",
    "    print(f\"Stimulus duration (s): {stim_duration_frames/framerate_hz}\")\n",
    "    print(f\"Frame duration (ms): {frame_time_s*1000}\")\n",
    "    print(f\"Framerate (Hz): %.2f\" % (framerate_hz))\n",
    "    return sync_info\n",
    "\n",
    "def process_trial(exp_dir:str, trial_dir:str, params:dict):\n",
    "    \"\"\"Process single trial\n",
    "    \n",
    "    Process a single imaging trial and save the processed tiff stack to the same directory as the original tiff stack.\n",
    "\n",
    "    An imaging trial can be split into 2+ videos due to tiff file size limits.\n",
    "\n",
    "    Stimulus is assumed to be in the first video.\n",
    "    \n",
    "    Inputs:\n",
    "        exp_dir: str \n",
    "            Experiment dir e.g. \"2024-03-06\"\n",
    "        trial_dir: str \n",
    "            Trial dir e.g. \"Zyla_15min_LHL_salineinj_1pt75pctISO_1\"\n",
    "    \"\"\"\n",
    "\n",
    "    trial_path, save_path = identify_trial_save_paths(exp_dir, trial_dir, params)\n",
    "\n",
    "    # load sync json if exists\n",
    "    if (save_path / \"sync_info.json\").exists():\n",
    "        with open(save_path / \"sync_info.json\", \"r\") as f:\n",
    "            sync_info = json.load(f)\n",
    "    else:\n",
    "        sync_info = {}\n",
    "        sync_info[\"stim_onset_frame\"] = 3000\n",
    "        print(f\"Warning: No sync_info.json found. Using default value of {sync_info['stim_onset_frame']} for stimulus onset time.\")\n",
    "    \n",
    "    # load processed tiff stack\n",
    "    fp_processed_tif = save_path / (params[\"preprocess_prefix\"] + trial_dir + \".tif\")\n",
    "    if not fp_processed_tif.exists():\n",
    "        raise FileNotFoundError(f\"Error: No preprocessed file exisits: {fp_processed_tif}\")\n",
    "\n",
    "    stack = io.imread(fp_processed_tif)\n",
    "    # crop image to remove the black border that occurs due to motion registration\n",
    "    crop_px = params[\"crop_px\"]\n",
    "    stack = stack[:, crop_px:-crop_px, crop_px:-crop_px]\n",
    "\n",
    "    # only process frames after stimulus onset\n",
    "    stack = stack[int((sync_info[\"stim_onset_frame\"]+50)/params['downsample_factor']):, :, :]\n",
    "\n",
    "    # find bottom X% of pixels in image\n",
    "    bottom10 = np.percentile(stack, params['bottom_percentile'], axis=(1,2), keepdims=True).astype(np.uint16)\n",
    "\n",
    "    # subtract bottom X% from all pixels\n",
    "    stack -= bottom10\n",
    "    stack -= stack.min(axis=0, keepdims=True)\n",
    "    stack[stack > 30000] = 0\n",
    "\n",
    "    # save tiff stack with the name of the first tiff in the stack\n",
    "    io.imsave(save_path / (params[\"process_prefix\"] + trial_dir + '.tif'), stack)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, tqdm\n",
    "from skimage.measure import block_reduce\n",
    "from neuroprocessing.align import StackAligner\n",
    "\n",
    "def preprocess_trial(exp_dir:str, trial_dir:str, params:dict):\n",
    "    \"\"\"Preprocessing of a single imaging trial\n",
    "\n",
    "    A single trial may have multiple videos due to tiff file size limits.\n",
    "        1. Downsample the tiff stack\n",
    "        2. Motion correction\n",
    "    \n",
    "        Notes: \n",
    "            - Tiff stacks with MMStack in the name will be processed and concatenated if there are multiple.\n",
    "        Usage:\n",
    "            preprocess_trial(\"2024-03-06\", \"Zyla_15min_LHL_salineinj_1pt75pctISO_1\", params)\n",
    "        \n",
    "    Inputs:\n",
    "        exp_dir: str \n",
    "            Experiment dir e.g. \"2024-03-06\"\n",
    "        trial_dir: str \n",
    "            Trial dir e.g. \"Zyla_15min_LHL_salineinj_1pt75pctISO_1\"\n",
    "    \"\"\"\n",
    "    \n",
    "    trial_path, save_path = identify_trial_save_paths(exp_dir, trial_dir, params)\n",
    "\n",
    "    fp_tifs = natsorted(Path(trial_path).glob(\"*MMStack*.tif\"))\n",
    "    fp_csv = natsorted(Path(trial_path).glob(\"*.csv\"))\n",
    "    \n",
    "    # if csv sync not found, ignore (**TODO** handle this)\n",
    "    if len(fp_csv) == 0:\n",
    "        print(f\"No sync file found in {trial_path}\")\n",
    "    else:\n",
    "        sync_info = _get_sync_info(fp_csv[0])\n",
    "        # save sync info as json\n",
    "        with open(save_path / \"sync_info.json\", \"w\") as f:\n",
    "            json.dump(sync_info, f)\n",
    "    \n",
    "    stack_list = []\n",
    "    for fp_tif in fp_tifs:\n",
    "        stack_list.append(io.imread(fp_tif))\n",
    "\n",
    "    # Downsample image\n",
    "    stack_downsampled = block_reduce(np.concatenate(stack_list, axis=0), block_size=(params['downsample_factor'], 1, 1), func=np.mean)\n",
    "\n",
    "    # temporarily save downsampled stack\n",
    "    # io.imsave(save_path / (\"downsampled_\" + trial_dir + \".tif\"), stack_downsampled.astype(np.uint16))\n",
    "    del(stack_list)\n",
    "\n",
    "    aligner = StackAligner(\n",
    "            stack=stack_downsampled,\n",
    "            target_num_features = params[\"aligner_target_num_features\"]\n",
    "        )\n",
    "    aligner.align()\n",
    "    \n",
    "    # save aligned stack\n",
    "    stack_aligned = aligner.stack_aligned\n",
    "\n",
    "    io.imsave(save_path / (params[\"preprocess_prefix\"] + trial_dir + \".tif\"), stack_aligned.astype(np.uint16))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"downsample_factor\": 8,\n",
    "    \"aligner_target_num_features\": 700,\n",
    "    \"preprocess_prefix\": \"aligned_downsampled_\",\n",
    "    \"process_prefix\": 'processed_',\n",
    "    \"s3fs_toplvl_path\": \"/Users/ilya_arcadia/arcadia-neuroimaging-pruritogens/Videos\",\n",
    "    \"local_toplvl_path\": \"/Users/ilya_arcadia/Neuroimaging_local/Processed/Injections/\",\n",
    "    \"load_from_s3\": True,\n",
    "    \"save_to_s3\": False,\n",
    "    'crop_px' : 20,\n",
    "    'bottom_percentile' : 10\n",
    "}\n",
    "\n",
    "def preprocess_and_process_trial(exp_dir:str, trial_dir:str, params:dict):\n",
    "    \"\"\"Preprocess and process a single trial\n",
    "    \n",
    "    Inputs:\n",
    "        exp_dir: str \n",
    "            Experiment dir e.g. \"2024-03-06\"\n",
    "        trial_dir: str \n",
    "            Trial dir e.g. \"Zyla_15min_LHL_salineinj_1pt75pctISO_1\"\n",
    "    \"\"\"\n",
    "    preprocess_trial(exp_dir, trial_dir, params)\n",
    "    process_trial(exp_dir, trial_dir, params)\n",
    "\n",
    "preprocess_and_process_trial(\"2024-03-06\", \"Zyla_15min_LHL_salineinj_1pt75pctISO_1\", params)\n",
    "preprocess_and_process_trial(\"2024-03-06\", \"Zyla_15min_RHL_salineinj_1pt25pctISO_1\", params)\n",
    "preprocess_and_process_trial(\"2024-03-06\", \"Zyla_30min_LHL_27mMhistinj_1pt75pctISO_1\", params)\n",
    "preprocess_and_process_trial(\"2024-03-06\", \"Zyla_30min_RHL_27mMhistinj_1pt25pctISO_1\", params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
